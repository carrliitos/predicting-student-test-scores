{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a84ec9-dcdc-4e65-993a-3c6ec27454e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'/kaggle/input/kaggle-utils/stat_funcs.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Projects/kaggle/predicting-student-test-scores/venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:701\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    700\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 701\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Projects/kaggle/predicting-student-test-scores/venv/lib/python3.10/site-packages/IPython/utils/path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mOSError\u001b[0m: File `'/kaggle/input/kaggle-utils/stat_funcs.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_palette(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhusl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# %run ../utils/stat_funcs.py\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/kaggle-utils/stat_funcs.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom functions are now available in the notebook namespace!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLibraries loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/kaggle/predicting-student-test-scores/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/Projects/kaggle/predicting-student-test-scores/venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:712\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    711\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 712\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[0;31mException\u001b[0m: File `'/kaggle/input/kaggle-utils/stat_funcs.py'` not found."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "ON_KAGGLE = Path(\"/kaggle\").exists()\n",
    "if ON_KAGGLE:\n",
    "    sys.path.insert(0, \"/kaggle/input/kaggle-utils\")\n",
    "    %run /kaggle/input/kaggle-utils/stat_funcs.py\n",
    "    train_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/train.csv\")\n",
    "    test_df  = pd.read_csv(\"/kaggle/input/playground-series-s6e1/test.csv\")\n",
    "else:\n",
    "    %run ../../utils/stat_funcs.py\n",
    "    train_df = pd.read_csv(\"../../data-raw/train.csv\")\n",
    "    test_df  = pd.read_csv(\"../../data-raw/test.csv\")\n",
    "\n",
    "print(\"custom functions are now available in the notebook namespace!\")\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c88d1-52e6-46c8-b53d-99ca3d1839b3",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Target column: `exam_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3876e3-f3d4-45c6-8b21-abe55091981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc86772-cb62-4a2e-942e-2142297b519b",
   "metadata": {},
   "source": [
    "Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6319bf-b342-4ca2-910d-7a31183bc212",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f701c58-3bbd-4cb3-a2a6-29f78ce9cfe5",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a31fa-fb12-469d-94cf-dc28cf1b8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb2ea2-2aaa-4e8d-8124-07601b9c3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"gender\", \"course\", \"internet_access\", \"sleep_quality\", \"study_method\", \"facility_rating\", \"exam_difficulty\"]:\n",
    "  train_df[col] = train_df[col].astype('category')\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bc120-f774-4292-a968-7cc4648cc9a8",
   "metadata": {},
   "source": [
    "Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2e99f-4c6e-4622-8c1f-c22c316ca375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5fdc8-24c8-4ebb-822f-6679dd5711e7",
   "metadata": {},
   "source": [
    "Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ac8f3-fdc8-496b-a7c5-31f946ff6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e905ab-f58e-4e7d-b2dd-864f756316b0",
   "metadata": {},
   "source": [
    "## What do we got?\n",
    "\n",
    "### Averages\n",
    "\n",
    "- 20.5 year old students,\n",
    "- who studies for 4 hours, and\n",
    "- are in class ~71.9% of the time.\n",
    "- They sleep about 7 hours,\n",
    "- and score about ~62.5%.\n",
    "\n",
    "### Extremes\n",
    "\n",
    "- We have students who are as young as 17 years and as old as 24 years.\n",
    "- Some students study for only 0.08 hours?! while others study for 8 hours.\n",
    "- We have some who are almost in all classes and others who are present only ~40% of the time.\n",
    "- Lowest exam score is 19.5% and the highest is 100%.\n",
    "\n",
    "### Other\n",
    "- No missing values in any variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e223dea-22cd-429c-af80-c560b878cccd",
   "metadata": {},
   "source": [
    "## Exam Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c89ef-0b96-4d7e-a553-40da5163b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(train_df['exam_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Exam Scores', fontsize=14)\n",
    "axes[0].set_xlabel('Exam Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(train_df['exam_score'], vert=True)\n",
    "axes[1].set_title('Box Plot of Exam Scores', fontsize=14)\n",
    "axes[1].set_ylabel('Exam Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b734c-4291-469e-980b-d9182d439e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean:   {train_df['exam_score'].mean():.2f}\")\n",
    "print(f\"Median: {train_df['exam_score'].median():.2f}\")\n",
    "print(f\"Std:    {train_df['exam_score'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673bbbf-3cc6-4899-973d-a6a70e2027f5",
   "metadata": {},
   "source": [
    "## Categorical Feature Analysis (univariate analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7611492-640d-4ef2-9ceb-9473886d5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10a1a3-043a-4a9b-b0b5-eaebeb008061",
   "metadata": {},
   "source": [
    "### Gender vs Exam Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9ff87-07f5-43ae-b8a6-2df829d61a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='gender', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Gender', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76d14b-f474-4074-a446-61e6f4eb6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"gender\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adca7d9-e9e4-4980-befa-70019d7d770c",
   "metadata": {},
   "source": [
    "One-way ANOVA via Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7b9af-39e0-49a6-bcfb-2f899f94ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.dropna(subset=[\"exam_score\", \"gender\"]).copy()\n",
    "\n",
    "model = smf.ols(\"exam_score ~ C(gender)\", data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca309e-b74c-4790-a37f-af61cbc2ad91",
   "metadata": {},
   "source": [
    "Eta-squared = SS_between / SS_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a28baa-3258-4929-9fb6-eede59d5c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_between = anova_table.loc[\"C(gender)\", \"sum_sq\"]\n",
    "ss_resid = anova_table.loc[\"Residual\", \"sum_sq\"]\n",
    "ss_total = ss_between + ss_resid\n",
    "eta_sq = ss_between / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19396c3d-2ad9-4738-837c-097b9739a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_table)\n",
    "print(f\"\\nEta-squared (η^2): {eta_sq:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eefdcf-f098-4f21-ba2c-dffcb3dd5c94",
   "metadata": {},
   "source": [
    "- **ANOVA result:** (F(`2`, `629,997`)=`55.43`), (`p`~ `8.5e-25`).\n",
    "  - With a sample this large, **at least one gender group mean differs from another** in a statistically detectable way.\n",
    "- **Effect size (η^2 = 0.000176):** This is the key interpretation for “how big.”\n",
    "  - eta^2 is the **proportion of total variation in exam scores explained by gender**.\n",
    "  - eta^2 = 0.000176 ~ 0.0176%\n",
    "\n",
    "So **gender explains about 0.018% of the variance** in exam scores - essentially none in practical terms.\n",
    "\n",
    "Even though the p-value is tiny (because we have ~630k rows), **gender is not meaningfully related to exam score** in terms of how much it helps explain or predict scores. The group means may differ by a small amount, but the difference is **very small relative to the overall spread of scores**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90ac16-f58a-4726-aedd-0c6683abaf2e",
   "metadata": {},
   "source": [
    "### Exam score by Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ea425-123f-42d2-a4a1-4a841f10fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='course', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Course', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05692d-e085-4774-b018-dfcbeb430a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"course\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984af36f-d738-41f0-b192-2ee7b1480099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.dropna(subset=[\"exam_score\", \"course\"]).copy()\n",
    "\n",
    "model = smf.ols(\"exam_score ~ C(course)\", data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "ss_between = anova_table.loc[\"C(course)\", \"sum_sq\"]\n",
    "ss_resid = anova_table.loc[\"Residual\", \"sum_sq\"]\n",
    "ss_total = ss_between + ss_resid\n",
    "eta_sq = ss_between / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c49bbe-9c24-47a4-9a8c-d291829ce31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_table)\n",
    "print(f\"\\nEta-squared (η^2): {eta_sq:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f9160-f3c8-49e5-91ee-cf73ad373a1b",
   "metadata": {},
   "source": [
    "- **ANOVA result:** (F(`6`, `629,993`)=`32.52`), (`p`~ `2.1e-39`).\n",
    "  - With a sample this large, **at least one course group mean differs from another** in a statistically detectable way.\n",
    "- **Effect size (η^2 = 0.000310):**\n",
    "  - eta^2 is the **proportion of total variation in exam scores explained by course**.\n",
    "  - eta^2 = 0.000310 ~ 0.0310%\n",
    "\n",
    "So **course explains about 0.031% of the variance** in exam scores - essentially none in practical terms.\n",
    "\n",
    "Even though the p-value is tiny (because we have ~630k rows), **course is not meaningfully related to exam score** in terms of how much it helps explain or predict scores. Any differences in course-level means exist, but they are **very small relative to the overall spread of scores**. Given the negligible η², any statistically significant pairwise differences between specific course categories are expected to be very small; interpret with effect sizes (e.g., Hedges’ g) rather than p-values alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f649c-314d-4620-9879-6c8e16a31542",
   "metadata": {},
   "source": [
    "### Exam score by Internet Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d8729-c993-4c8d-b348-19be441c6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='internet_access', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Internet Access', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5a5c3-7f37-4b22-85c1-ac59b407531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"internet_access\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cbb4d-cb76-4b9a-97dd-cc1f2ddb5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_access_yes = train_df[train_df[\"internet_access\"]==\"yes\"][\"exam_score\"].to_numpy()\n",
    "internet_access_no = train_df[train_df[\"internet_access\"]==\"no\"][\"exam_score\"].to_numpy()\n",
    "\n",
    "print(f\"Cohen's D: {cohend(internet_access_yes, internet_access_no):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8492d5b-9dbb-45d7-a57d-c93c59932bba",
   "metadata": {},
   "source": [
    "#### Cohen's D interpretation\n",
    "\n",
    "**Intuition**\n",
    "- d = 0: the group averages are the same.\n",
    "- d = 1: the averages are one standard deviation apart (that’s pretty noticeable).\n",
    "- d = 0.5: half a standard deviation apart (moderate).\n",
    "- d = 0.2: small difference.\n",
    "\n",
    "**Common rule-of-thumb (very rough)**\n",
    "- 0.2 = small\n",
    "- 0.5 = medium\n",
    "- 0.8 = large\n",
    "\n",
    "With **exam score** as the outcome:\n",
    "\n",
    "- Mean (no internet) = **62.48**\n",
    "- Mean (yes internet) = **62.51**\n",
    "- Difference = **~0.03 points**\n",
    "- **Cohen’s d = 0.0016** = **basically zero effect**\n",
    "\n",
    "Students with and without internet access scored **about the same** on the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be9243-064f-46df-99f1-bc6f45392b56",
   "metadata": {},
   "source": [
    "### Exam Score vs Sleep Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4decf2a-4e8c-4702-8f95-482e3609e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='sleep_quality', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Sleep Quality', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5782d-a0e0-4387-947c-6183af0b4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"sleep_quality\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1b984-ed13-4347-90c5-6b2d3f443566",
   "metadata": {},
   "source": [
    "### Exam Score vs study method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09d86f-e419-40b1-acdd-508678cdd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='study_method', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Study Method', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e8662-52ed-424e-b677-66ff5efb1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"study_method\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036aa5da-2002-4137-b564-419956af6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.dropna(subset=[\"exam_score\", \"study_method\"]).copy()\n",
    "\n",
    "model = smf.ols(\"exam_score ~ C(study_method)\", data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "ss_between = anova_table.loc[\"C(study_method)\", \"sum_sq\"]\n",
    "ss_resid = anova_table.loc[\"Residual\", \"sum_sq\"]\n",
    "ss_total = ss_between + ss_resid\n",
    "eta_sq = ss_between / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336220e-b2d5-4cdc-b11c-53b77343ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_table)\n",
    "print(f\"\\nEta-squared (η²): {eta_sq:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017723ef-d999-4ab8-a99e-5bd1cbdd8663",
   "metadata": {},
   "source": [
    "- **ANOVA result:** (F(`4`, `629,995`)=`8304.29`), (`p` ~ `0.0`).\n",
    "  - With a sample this large, **at least one study method group mean differs from another** in a statistically detectable way.\n",
    "- **Effect size (η² = 0.050085):**\n",
    "  - eta^2 is the **proportion of total variation in exam scores explained by study_method**.\n",
    "  - eta^2 = 0.050085 ~ 5.01%\n",
    "\n",
    "So **study_method explains about 5.0% of the variance** in exam scores - a **meaningful** relationship (small-to-moderate).\n",
    "\n",
    "Unlike gender/course (where η² was near zero), here the differences are also obvious in the group means:\n",
    "- coaching: **69.27**\n",
    "- mixed: **65.10**\n",
    "- group study: **60.53**\n",
    "- online videos: **59.73**\n",
    "- self-study: **57.70**\n",
    "\n",
    "That’s roughly an **~11.6 point spread** from coaching to self-study, which is large relative to the within-group SDs (~18–19). This is why the effect size is non-negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479af3f-52be-4183-838c-dda26e53a6ac",
   "metadata": {},
   "source": [
    "### Exam SCore by facility rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aca223-f938-4f0a-8d61-0cdaae802197",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='facility_rating', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Facility Rating', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac9df7-4459-493e-99df-254366cfc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"facility_rating\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b9d5a-f92a-4ee5-8c88-d72edfc1b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.dropna(subset=[\"exam_score\", \"facility_rating\"]).copy()\n",
    "\n",
    "model = smf.ols(\"exam_score ~ C(facility_rating)\", data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "ss_between = anova_table.loc[\"C(facility_rating)\", \"sum_sq\"]\n",
    "ss_resid = anova_table.loc[\"Residual\", \"sum_sq\"]\n",
    "ss_total = ss_between + ss_resid\n",
    "eta_sq = ss_between / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d6f1b-3fec-4ea4-8826-df9230104831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_table)\n",
    "print(f\"\\nEta-squared (η²): {eta_sq:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5216d-5d99-47e6-9052-8deb44a1388e",
   "metadata": {},
   "source": [
    "- **ANOVA result:** (F(`2`, `629,997`)=`11664.97`), (`p` ~ `0.0`).\n",
    "  - With a sample this large, **at least one facility_rating group mean differs from another** in a statistically detectable way.\n",
    "- **Effect size (η² = 0.035709):**\n",
    "  - eta^2 is the **proportion of total variation in exam scores explained by facility_rating**.\n",
    "  - eta^2 = 0.035709 ~ 3.57%\n",
    "\n",
    "So **facility_rating explains about 3.6% of the variance** in exam scores - a **meaningful** relationship (small-to-moderate).\n",
    "\n",
    "The group means show clear practical separation:\n",
    "- **high:** 66.71  \n",
    "- **medium:** 63.03  \n",
    "- **low:** 57.95  \n",
    "\n",
    "That’s an **~8.75 point** difference between high vs low, which is sizeable relative to the within-group SDs (~18.5–18.6), consistent with the non-negligible η²."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f20472-0ee6-419e-9111-7819fca6d682",
   "metadata": {},
   "source": [
    "### Exam Score by Exam Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e7b3e-0470-4247-9784-05b9afada419",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "sns.boxplot(data=train_df, x='exam_difficulty', y='exam_score', ax=ax)\n",
    "ax.set_title('Exam Score by Exam Difficulty', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0891b-7d1d-455f-8f52-5537f20d56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    train_df.groupby(\"exam_difficulty\")[\"exam_score\"]\n",
    "            .agg(\n",
    "                n=\"count\",\n",
    "                mean=\"mean\",\n",
    "                median=\"median\",\n",
    "                std=\"std\",\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75)\n",
    "            )\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24862c70-325f-434f-90b0-ca2f3fb364e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.dropna(subset=[\"exam_score\", \"exam_difficulty\"]).copy()\n",
    "\n",
    "model = smf.ols(\"exam_score ~ C(exam_difficulty)\", data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "ss_between = anova_table.loc[\"C(exam_difficulty)\", \"sum_sq\"]\n",
    "ss_resid = anova_table.loc[\"Residual\", \"sum_sq\"]\n",
    "ss_total = ss_between + ss_resid\n",
    "eta_sq = ss_between / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487028cc-74c6-45df-98fb-57feb8b2b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_table)\n",
    "print(f\"\\nEta-squared (η²): {eta_sq:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633e062-16e8-4738-bacc-ad57abd78196",
   "metadata": {},
   "source": [
    "- **ANOVA result:** (F(`2`, `629,997`)=`29.74`), (`p`~ `1.21e-13`).\n",
    "  - With a sample this large, **at least one exam_difficulty group mean differs from another** in a statistically detectable way.\n",
    "- **Effect size (η² = 0.000094):**\n",
    "  - eta^2 is the **proportion of total variation in exam scores explained by exam_difficulty**.\n",
    "  - eta^2 = 0.000094 ~ 0.0094%\n",
    "\n",
    "So **exam_difficulty explains about 0.009% of the variance** in exam scores - essentially none in practical terms.\n",
    "\n",
    "The group means are nearly identical:\n",
    "- **easy:** 62.21  \n",
    "- **moderate:** 62.61  \n",
    "- **hard:** 62.67  \n",
    "\n",
    "The largest gap (hard vs easy) is only **~0.46 points**, which is tiny relative to the within-group SDs (~19). That’s why the p-value is very small (huge N), but the effect size is negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec9031-7c9b-4217-bf9f-4d2839a5ad24",
   "metadata": {},
   "source": [
    "## Numerical Feature Analysis\n",
    "\n",
    "| Column           | Data Type |\n",
    "|------------------|-----------|\n",
    "| age              | int64     | \n",
    "| study_hours      | float64   | \n",
    "| class_attendance | float64   | \n",
    "| sleep_hours      | float64   | \n",
    "| exam_score       | float64   | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b14669-5eb2-45ab-9464-e70f9fcbcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'study_hours', 'class_attendance', 'sleep_hours', 'exam_score']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation = train_df[num_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, fmt='.3f', linewidths=0.5)\n",
    "\n",
    "plt.title('Correlation Heatmap', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e32aa1-dc14-4635-91e4-ceec8d13bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_string = correlation.round(3)\n",
    "print(corr_string.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626b9dc-8e6e-4c3c-8074-a2a45d549617",
   "metadata": {},
   "source": [
    "### Correlation summary (Pearson r)\n",
    "\n",
    "Correlations with exam_score:\n",
    "- `study_hours`: r = 0.762  (strong positive association)\n",
    "- `class_attendance`: r = 0.361  (moderate positive association)\n",
    "- `sleep_hours`: r = 0.167  (weak positive association)\n",
    "- `age`: r = 0.010  (essentially no association)\n",
    "\n",
    "Other notable relationships among predictors:\n",
    "- `study_hours` vs `class_attendance`: r = 0.088 (very weak positive)\n",
    "- `study_hours` vs `sleep_hours`: r = 0.042 (very weak positive)\n",
    "- `class_attendance` vs `sleep_hours`: r = 0.029 (very weak positive)\n",
    "- `age` has near-zero correlation with the other variables (|r| ~ 0.006-0.011)\n",
    "\n",
    "Exam scores are most strongly associated with `study_hours`, with smaller (but still positive) associations for `class_attendance` and `sleep_hours`. Age appears unrelated to exam performance in this dataset. Also, the predictors are not strongly correlated with each other, so multicollinearity is unlikely to be a major concern for a basic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69ed99-92a1-4053-9393-d83a12896c00",
   "metadata": {},
   "source": [
    "## Overall EDA Summary\n",
    "\n",
    "### Dataset overview \n",
    "\n",
    "The training data contains **630,000 rows** and **13 columns**, with the target variable **`exam_score`** (continuous, 0-100 scale). An **`id`** column is a unique identifier (sequential from 0 to 629,999) and is not inherently predictive. The `id` column would need to be removed during feature engineering.\n",
    "\n",
    "- **Data quality:**\n",
    "  - **No missing values** across any features or the target.\n",
    "  - Data types are clean and appropriate after casting:\n",
    "    - **Numeric:** `age`, `study_hours`, `class_attendance`, `sleep_hours`, `exam_score`\n",
    "    - **Categorical:** `gender`, `course`, `internet_access`, `sleep_quality`, `study_method`, `facility_rating`, `exam_difficulty`\n",
    "- **Typical student profile (central tendency):**\n",
    "  - **Age:** ~**20.55** years (median **21**, range **17-24**)\n",
    "  - **Study hours:** mean ~**4.00** (median **4.00**, range **0.08-7.91**)\n",
    "  - **Class attendance (%):** mean ~**71.99** (median **72.6**, range **40.6-99.4**)\n",
    "  - **Sleep hours:** mean ~**7.07** (median **7.1**, range **4.1-9.9**)\n",
    "  - **Exam score:** mean ~**62.51** (median **62.6**, range **19.6-100**)\n",
    "- **Spread / variability:**\n",
    "  - `exam_score` has **substantial variability** (std ~**18.92**), suggesting meaningful separation between low- and high-performing students.\n",
    "  - `class_attendance` also varies widely (std ~**17.43**), while `age` is comparatively tight (std ~**2.26**).\n",
    "- **Notable extremes & sanity checks:**\n",
    "  - Very low study time values exist (down to **0.08 hours**), and attendance can be as low as **~40%**, which may represent legitimately low-engagement students rather than data issues (since missingness is zero and ranges look plausible).\n",
    "  - Scores span almost the entire possible scale (**~20 to 100**), indicating no obvious clipping problems.\n",
    "- **Model-readiness implications:**\n",
    "  - This is a **mixed-type regression problem** with several categorical predictors that will require **encoding** (one-hot or target/ordinal encoding depending on the feature).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898252e4-1eeb-431d-a3e9-d79b7398a729",
   "metadata": {},
   "source": [
    "## 2026-01-21\n",
    "\n",
    "I'm a Chris Deotte fan, and [his EDA](https://www.kaggle.com/code/cdeotte/basic-eda-lots-of-linear-relationships) says:\n",
    "- We can convert `age` to a categorical due to its low cardinality\n",
    "- We need to start caring about ordinal classes\n",
    "- We can see many nearly uniform linear distribution\n",
    "- Many features have a linear relationship with `exam_score`\n",
    "- And importantly,\n",
    "  >All features appear to be predictive of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c1e120-4533-427a-844c-5f06564ef2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
